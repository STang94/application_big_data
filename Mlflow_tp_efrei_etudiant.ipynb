{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP MLFLOW\n",
    "Florent Jakubowski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Prise en main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Installez le package mlflow avec python dans un environnement virtuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Dans un terminal lancez un serveur mlflow. Aller voir dans votre navigateur, sur le port correspondant, l'ui de mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque vous lancez mflow sans option par défaut mlflow va stocker toute la donnée dont il a besoin sur votre file system. Vous aurez notamment un dossier mlruns qui se créra par défaut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Dans un notebook, utilisez le package mlflow pour vous connecter au serveur mlflow que vous avez lancé. Utilisez la bonne fonction pour paramétrer l'adresse du serveur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\pydantic\\_internal\\_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set the MLflow tracking URI to the address of your server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Example: Track a metric and parameter\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 10.2)\n",
    "\n",
    "# To stop tracking in this run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention ! A chaque fois que vous effectuerez une opération sur mlflow dans une autre cellule de votre notebook vous devrez vérifier avant que vous pointez bien sur le bon serveur mlflow. Il existe aussi une fonction pour connaître quelle adresse de serveur a été enregistrée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adresse actuelle du serveur MLflow : http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Obtenir l'adresse actuelle du serveur MLflow\n",
    "current_tracking_uri = mlflow.get_tracking_uri()\n",
    "print(f\"Adresse actuelle du serveur MLflow : {current_tracking_uri}\")\n",
    "\n",
    "# On peut changer l'adresse du serveur avec cette commande\n",
    "# mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez une experiment via votre notebook ou avec via l'ui. \n",
    "Une experiment, ou une expérience en français, est un ensemble de run que vous avez effectué. Le but est de trouver in fine les meilleurs paramètres, modèles ou hyperparamètres pour votre besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_ALREADY_EXISTS: Experiment 'test' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ecole d'inge\\Application of big data\\Mlflow_tp_efrei_etudiant.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Set the MLflow tracking URI to the address of your server\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mlflow\u001b[39m.\u001b[39mset_tracking_uri(\u001b[39m\"\u001b[39m\u001b[39mhttp://127.0.0.1:5000\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39;49mcreate_experiment(\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\tracking\\fluent.py:1538\u001b[0m, in \u001b[0;36mcreate_experiment\u001b[1;34m(name, artifact_location, tags)\u001b[0m\n\u001b[0;32m   1493\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_experiment\u001b[39m(\n\u001b[0;32m   1494\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   1495\u001b[0m     artifact_location: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1496\u001b[0m     tags: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1497\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m   1498\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[39m    Create an experiment.\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1538\u001b[0m     \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39;49mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\tracking\\client.py:563\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[1;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_experiment\u001b[39m(\n\u001b[0;32m    516\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    517\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    518\u001b[0m     artifact_location: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    519\u001b[0m     tags: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    520\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    521\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \n\u001b[0;32m    523\u001b[0m \u001b[39m    :param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39m        Lifecycle_stage: active\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tracking_client\u001b[39m.\u001b[39;49mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:235\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[1;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m:param name: The experiment name. Must be unique.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39m:return: Integer ID of the created experiment.\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[1;32m--> 235\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstore\u001b[39m.\u001b[39;49mcreate_experiment(\n\u001b[0;32m    236\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    237\u001b[0m     artifact_location\u001b[39m=\u001b[39;49martifact_location,\n\u001b[0;32m    238\u001b[0m     tags\u001b[39m=\u001b[39;49m[ExperimentTag(key, value) \u001b[39mfor\u001b[39;49;00m (key, value) \u001b[39min\u001b[39;49;00m tags\u001b[39m.\u001b[39;49mitems()] \u001b[39mif\u001b[39;49;00m tags \u001b[39melse\u001b[39;49;00m [],\n\u001b[0;32m    239\u001b[0m )\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:98\u001b[0m, in \u001b[0;36mRestStore.create_experiment\u001b[1;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[0;32m     94\u001b[0m tag_protos \u001b[39m=\u001b[39m [tag\u001b[39m.\u001b[39mto_proto() \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags] \u001b[39mif\u001b[39;00m tags \u001b[39melse\u001b[39;00m []\n\u001b[0;32m     95\u001b[0m req_body \u001b[39m=\u001b[39m message_to_json(\n\u001b[0;32m     96\u001b[0m     CreateExperiment(name\u001b[39m=\u001b[39mname, artifact_location\u001b[39m=\u001b[39martifact_location, tags\u001b[39m=\u001b[39mtag_protos)\n\u001b[0;32m     97\u001b[0m )\n\u001b[1;32m---> 98\u001b[0m response_proto \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_endpoint(CreateExperiment, req_body)\n\u001b[0;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m response_proto\u001b[39m.\u001b[39mexperiment_id\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body)\u001b[0m\n\u001b[0;32m     57\u001b[0m endpoint, method \u001b[39m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[0;32m     58\u001b[0m response_proto \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mResponse()\n\u001b[1;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m call_endpoint(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_host_creds(), endpoint, method, json_body, response_proto)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:210\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[0;32m    208\u001b[0m     call_kwargs[\u001b[39m\"\u001b[39m\u001b[39mjson\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m json_body\n\u001b[0;32m    209\u001b[0m     response \u001b[39m=\u001b[39m http_request(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcall_kwargs)\n\u001b[1;32m--> 210\u001b[0m response \u001b[39m=\u001b[39m verify_rest_response(response, endpoint)\n\u001b[0;32m    211\u001b[0m js_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext)\n\u001b[0;32m    212\u001b[0m parse_dict(js_dict\u001b[39m=\u001b[39mjs_dict, message\u001b[39m=\u001b[39mresponse_proto)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\utils\\rest_utils.py:142\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[1;34m(response, endpoint)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m _can_parse_as_json_object(response\u001b[39m.\u001b[39mtext):\n\u001b[1;32m--> 142\u001b[0m         \u001b[39mraise\u001b[39;00m RestException(json\u001b[39m.\u001b[39mloads(response\u001b[39m.\u001b[39mtext))\n\u001b[0;32m    143\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m         base_msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    145\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAPI request to endpoint \u001b[39m\u001b[39m{\u001b[39;00mendpoint\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfailed with error code \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m != 200\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         )\n",
      "\u001b[1;31mRestException\u001b[0m: RESOURCE_ALREADY_EXISTS: Experiment 'test' already exists."
     ]
    }
   ],
   "source": [
    "# Set the MLflow tracking URI to the address of your server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "id = mlflow.create_experiment(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareillement à l'adresse du serveur mlflow à chaque fois que vous exécuterez un run dans une cellule vous devrez définir l'experiment sur laquelle vous voulez envoyer votre run. Cherchez dans la documentation la fonction permettant de faire cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Invalid experiment id: <built-in function id> of type <class 'builtin_function_or_method'>. Must be one of str, int, or None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ecole d'inge\\Application of big data\\Mlflow_tp_efrei_etudiant.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Example: Track a metric and parameter\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39;49mstart_run(experiment_id\u001b[39m=\u001b[39;49m\u001b[39mid\u001b[39;49m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_param(\u001b[39m\"\u001b[39m\u001b[39mparam1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mmetric1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m10.2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\tracking\\fluent.py:294\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mStart a new MLflow run, setting it as the active run under which metrics and parameters\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mwill be logged. The return value can be used as a context manager within a ``with`` block;\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m    0  7d175204675e40328e46d9a6a5a7ee6a          yes           CHILD_RUN\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39mglobal\u001b[39;00m _active_run_stack\n\u001b[1;32m--> 294\u001b[0m _validate_experiment_id_type(experiment_id)\n\u001b[0;32m    295\u001b[0m \u001b[39m# back compat for int experiment_id\u001b[39;00m\n\u001b[0;32m    296\u001b[0m experiment_id \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(experiment_id) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(experiment_id, \u001b[39mint\u001b[39m) \u001b[39melse\u001b[39;00m experiment_id\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\mlflow\\utils\\validation.py:359\u001b[0m, in \u001b[0;36m_validate_experiment_id_type\u001b[1;34m(experiment_id)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[39mCheck that a user-provided experiment_id is either a string, int, or None and raise an\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39mexception if it isn't.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m experiment_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(experiment_id, (\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m)):\n\u001b[1;32m--> 359\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    360\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid experiment id: \u001b[39m\u001b[39m{\u001b[39;00mexperiment_id\u001b[39m}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(experiment_id)\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust be one of str, int, or None.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    362\u001b[0m         error_code\u001b[39m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m    363\u001b[0m     )\n",
      "\u001b[1;31mMlflowException\u001b[0m: Invalid experiment id: <built-in function id> of type <class 'builtin_function_or_method'>. Must be one of str, int, or None."
     ]
    }
   ],
   "source": [
    "# Example: Track a metric and parameter\n",
    "with mlflow.start_run(experiment_id=id):\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 10.2)\n",
    "    \n",
    "\n",
    "# To stop tracking in this run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = mlflow.get_experiment_by_name(\"tet\")\n",
    "type(test)\n",
    "test==None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vous proposons de créer une fonction `configure_experiment` permettant de créer une expérience ou de définir l'expérience si elle existe déjà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    # Commencer un nouveau run dans l'expérience existante\\n    with mlflow.start_run(experiment_id=experiment_id):\\n        for key,value in params:\\n             mlflow.log_param(key, value)\\n        for key,value in metrics:\\n            mlflow.log_metric(key, value)\\n        for key,value in tags:\\n            mlflow.set_tag(key, value)\\n        for path in artifacts:\\n            mlflow.log_artifact(path)\\n        # To stop tracking in this run\\n    mlflow.end_run()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def configure_experiment(name:str, params:dict={\"\",\"\"},metrics:dict={\"\",\"\"},tags:dict={\"\",\"\"}, artifacts:list=[\"\"]):\n",
    "\n",
    "    # track du serveur\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "    if mlflow.get_experiment_by_name(name) is None:\n",
    "        \n",
    "        return mlflow.create_experiment(name)\n",
    "        \n",
    "    else :\n",
    "        # Récupérer l'ID de l'expérience\n",
    "        return mlflow.get_experiment_by_name(name).experiment_id\n",
    "\"\"\"\n",
    "    # Commencer un nouveau run dans l'expérience existante\n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "        for key,value in params:\n",
    "             mlflow.log_param(key, value)\n",
    "        for key,value in metrics:\n",
    "            mlflow.log_metric(key, value)\n",
    "        for key,value in tags:\n",
    "            mlflow.set_tag(key, value)\n",
    "        for path in artifacts:\n",
    "            mlflow.log_artifact(path)\n",
    "        # To stop tracking in this run\n",
    "    mlflow.end_run()\n",
    "\"\"\"\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Après avoir créé l'experiment. Nous allons entraîner notre modèle. Prenez le dataset wine de la librairie sklearn et utilisez un algorithme de la famille des arbres de décisions. Nous allons lors de l'entraînement de notre modèle logger les mesures.   \n",
    "\n",
    "Pour cela nous voulons lancer un nouveau run dans notre experiment sur mlflow. Le run correspond à un entraînement du modèle.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Créer une variable run_name pour le nouveau run que vous voulez créer avec la date du jour, l'heure, la minute et la seconde dans le nom.   \n",
    "-Trouvez comment logger les paramètres d'entraînement, les hyperparamètres et les performances du modèle (metrics) explicitement dans mlflow en lançant votre run de manière manuelle.   \n",
    "-Ajoutez également votre modèle avec un nom distinctif grâce à la méthode adéquat, vous devrez réutiliser ce nom lors des prochains entraînements. Que voyez-vous dans l'ui de mlflow ?   \n",
    "\n",
    "\n",
    "Vous pouvez utiliser `with` pour ne pas avoir besoin d'utiliser la fonction `end_run()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset Wine\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser le dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Paramètres de l'algorithme de l'arbre de décision\n",
    "tree_params = {\n",
    "    'criterion': 'gini',\n",
    "    'max_depth': 3,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# track du serveur\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "        \n",
    "experiment_id = configure_experiment(\"wine_classification_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'183478325808655477'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id,run_name=f\"run_{datetime.datetime.now().strftime('%Y/%m/%d_%H:%M:%S')}\"):\n",
    "    for key, value in tree_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "        \n",
    "    # Initialiser et entraîner le modèle\n",
    "    model = DecisionTreeClassifier(**tree_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "     # Calcul des métriques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Log des métriques\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Log des artefacts (le modèle)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Ajouter le modèle avec un nom distinctif\n",
    "    model_name = \"decision_tree_model\"\n",
    "    mlflow.sklearn.log_model(model, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser `mlflow.active_run()` pour être sûr que le run est bien terminé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Afficher le résultat du run (ID du run)\n",
    "print(mlflow.active_run())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecrivez un run sans utiliser un with et sans utilisez mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: <ActiveRun: >\n"
     ]
    }
   ],
   "source": [
    "mlflow.start_run(experiment_id=experiment_id,run_name=f\"run_{datetime.datetime.now().strftime('%Y/%m/%d_%H:%M:%S')}\")\n",
    "for key, value in tree_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "        \n",
    "    # Initialiser et entraîner le modèle\n",
    "model = DecisionTreeClassifier(**tree_params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "    # Calcul des métriques\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Log des métriques\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Log des artefacts (le modèle)\n",
    "mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Ajouter le modèle avec un nom distinctif\n",
    "model_name = \"decision_tree_model\"\n",
    "mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "# Afficher le résultat du run (ID du run)\n",
    "print(f\"Run ID: {mlflow.active_run()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `active_run()` nous retourne normalement ce run ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ActiveRun: >\n"
     ]
    }
   ],
   "source": [
    "run = mlflow.active_run()\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faisons bien attention de bien le fermer pour ne pas avoir de comportements exotiques ensuite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez mlflow.end_run() et vérifiez avec active_run() qu'aucun run n'est retourné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "print(mlflow.active_run())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe une autre manière de logger automatiquement des paramètres et des metrics à vous de la trouver.   \n",
    "(Attention une fois activée cette fonction entrainera toujours un log automatique, veillez à la désactiver pour la suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.sklearn import autolog\n",
    "# Activer le suivi automatique pour scikit-learn\n",
    "autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Changez un ou plusieurs hyperparamètres et relancez un entraînement avec le même nom de modèle. Rendez-vous dans l'onglet model de mlflow que constatez-vous ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.sklearn import autolog\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger le dataset Wine\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Diviser le dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Paramètres de l'algorithme de l'arbre de décision\n",
    "tree_params = {\n",
    "    'criterion': 'entropy',  # Changer un hyperparamètre\n",
    "    'max_depth': 5,           # Changer un autre hyperparamètre\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Configuration de l'expérience dans MLflow\n",
    "experiment_name = \"wine_classification_experiment\"\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "experiment_id = configure_experiment(experiment_name)\n",
    "\n",
    "# Commencer un nouveau run avec le même nom de modèle\n",
    "with mlflow.start_run(experiment_id=experiment_id,run_name=f\"run_{datetime.datetime.now().strftime('%Y/%m/%d_%H:%M:%S')}\"):\n",
    "    for key, value in tree_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "        \n",
    "    # Initialiser et entraîner le modèle\n",
    "    model = DecisionTreeClassifier(**tree_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "     # Calcul des métriques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Log des métriques\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Log des artefacts (le modèle)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Ajouter le modèle avec un nom distinctif\n",
    "    model_name = \"decision_tree_model\"\n",
    "    mlflow.sklearn.log_model(model, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez récupérer le dernier run avec la fonction last_active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run: data=<RunData: metrics={'accuracy': 0.9166666666666666}, params={'criterion': 'entropy', 'max_depth': '5', 'random_state': '42'}, tags={'mlflow.log-model.history': '[{\"run_id\": \"3ca200ab28e74974b6d57f69a393ffbd\", '\n",
      "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
      "                             '\"2023-11-15 13:10:06.106951\", \"flavors\": '\n",
      "                             '{\"python_function\": {\"model_path\": \"model.pkl\", '\n",
      "                             '\"predict_fn\": \"predict\", \"loader_module\": '\n",
      "                             '\"mlflow.sklearn\", \"python_version\": \"3.9.18\", '\n",
      "                             '\"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": '\n",
      "                             '\"python_env.yaml\"}}, \"sklearn\": '\n",
      "                             '{\"pickled_model\": \"model.pkl\", '\n",
      "                             '\"sklearn_version\": \"1.3.2\", '\n",
      "                             '\"serialization_format\": \"cloudpickle\", \"code\": '\n",
      "                             'null}}, \"model_uuid\": '\n",
      "                             '\"79f2c7365ab34864ba6d2742c16729f6\", '\n",
      "                             '\"mlflow_version\": \"2.8.0\", \"model_size_bytes\": '\n",
      "                             '2270}, {\"run_id\": '\n",
      "                             '\"3ca200ab28e74974b6d57f69a393ffbd\", '\n",
      "                             '\"artifact_path\": \"decision_tree_model\", '\n",
      "                             '\"utc_time_created\": \"2023-11-15 '\n",
      "                             '13:10:08.885443\", \"flavors\": {\"python_function\": '\n",
      "                             '{\"model_path\": \"model.pkl\", \"predict_fn\": '\n",
      "                             '\"predict\", \"loader_module\": \"mlflow.sklearn\", '\n",
      "                             '\"python_version\": \"3.9.18\", \"env\": {\"conda\": '\n",
      "                             '\"conda.yaml\", \"virtualenv\": \"python_env.yaml\"}}, '\n",
      "                             '\"sklearn\": {\"pickled_model\": \"model.pkl\", '\n",
      "                             '\"sklearn_version\": \"1.3.2\", '\n",
      "                             '\"serialization_format\": \"cloudpickle\", \"code\": '\n",
      "                             'null}}, \"model_uuid\": '\n",
      "                             '\"20b5ec08228d4996a8f1302f0ba5aae0\", '\n",
      "                             '\"mlflow_version\": \"2.8.0\", \"model_size_bytes\": '\n",
      "                             '2270}]',\n",
      " 'mlflow.runName': 'run_2023/11/15_14:10:06',\n",
      " 'mlflow.source.name': \"c:\\\\Ecole d'inge\\\\Application of big \"\n",
      "                       'data\\\\venv\\\\lib\\\\site-packages\\\\ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'tangs'}>, info=<RunInfo: artifact_uri='mlflow-artifacts:/183478325808655477/3ca200ab28e74974b6d57f69a393ffbd/artifacts', end_time=1700053811727, experiment_id='183478325808655477', lifecycle_stage='active', run_id='3ca200ab28e74974b6d57f69a393ffbd', run_name='run_2023/11/15_14:10:06', run_uuid='3ca200ab28e74974b6d57f69a393ffbd', start_time=1700053806014, status='FINISHED', user_id='tangs'>, inputs=<RunInputs: dataset_inputs=[]>>\n"
     ]
    }
   ],
   "source": [
    "run = mlflow.last_active_run() \n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Entraîner 3,4 modèles avec des hyperparamètres différents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.sklearn import autolog\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger le dataset Wine\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Diviser le dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Paramètres de l'algorithme de l'arbre de décision\n",
    "tree_params = {\n",
    "    'criterion': 'log_loss',  # Changer un hyperparamètre\n",
    "    'max_depth': 9,           # Changer un autre hyperparamètre\n",
    "    'random_state': 36\n",
    "}\n",
    "\n",
    "# Configuration de l'expérience dans MLflow\n",
    "experiment_name = \"wine_classification_experiment\"\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "experiment_id = configure_experiment(experiment_name)\n",
    "\n",
    "# Commencer un nouveau run avec le même nom de modèle\n",
    "with mlflow.start_run(experiment_id=experiment_id,run_name=f\"run_{datetime.datetime.now().strftime('%Y/%m/%d_%H:%M:%S')}\"):\n",
    "    for key, value in tree_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "        \n",
    "    # Initialiser et entraîner le modèle\n",
    "    model = DecisionTreeClassifier(**tree_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "     # Calcul des métriques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Log des métriques\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Log des artefacts (le modèle)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Ajouter le modèle avec un nom distinctif\n",
    "    model_name = \"decision_tree_model\"\n",
    "    mlflow.sklearn.log_model(model, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.sklearn import autolog\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger le dataset Wine\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Diviser le dataset en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Paramètres de l'algorithme de l'arbre de décision\n",
    "tree_params = {\n",
    "    'criterion': 'gini',  # Changer un hyperparamètre\n",
    "    'max_depth': 13,           # Changer un autre hyperparamètre\n",
    "    'random_state': 50\n",
    "}\n",
    "\n",
    "# Configuration de l'expérience dans MLflow\n",
    "experiment_name = \"wine_classification_experiment\"\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "experiment_id = configure_experiment(experiment_name)\n",
    "\n",
    "# Commencer un nouveau run avec le même nom de modèle\n",
    "with mlflow.start_run(experiment_id=experiment_id,run_name=f\"run_{datetime.datetime.now().strftime('%Y/%m/%d_%H:%M:%S')}\"):\n",
    "    for key, value in tree_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "        \n",
    "    # Initialiser et entraîner le modèle\n",
    "    model = DecisionTreeClassifier(**tree_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "     # Calcul des métriques\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Log des métriques\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Log des artefacts (le modèle)\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Ajouter le modèle avec un nom distinctif\n",
    "    model_name = \"decision_tree_model\"\n",
    "    mlflow.sklearn.log_model(model, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Versionning des données avec DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque run le dataset utilisé est précisé dans mlflow. Mais les informations fournies sont assez pauvres. Pour améliorer ça nous allons utiliser l'outil dvc en combinaison avec mlflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dvc fonctionne de pair avec git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisez un repo git localement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in C:/Ecole d'inge/Application of big data/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installez dvc avec pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dvc in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (3.29.0)\n",
      "Requirement already satisfied: pyparsing>=2.4.7 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (3.1.1)\n",
      "Requirement already satisfied: tomlkit>=0.11.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.12.3)\n",
      "Requirement already satisfied: psutil>=5.8 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (5.9.6)\n",
      "Requirement already satisfied: tqdm<5,>=4.63.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (4.66.1)\n",
      "Requirement already satisfied: iterative-telemetry>=0.0.7 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.0.8)\n",
      "Requirement already satisfied: requests>=2.22 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (2.31.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (1.3.2)\n",
      "Requirement already satisfied: zc.lockfile>=1.2.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (3.0.post1)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.11 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.18.5)\n",
      "Requirement already satisfied: distro>=1.3 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (1.8.0)\n",
      "Requirement already satisfied: pydot>=1.2.4 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (1.4.2)\n",
      "Requirement already satisfied: funcy>=1.14 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.7 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.9.0)\n",
      "Requirement already satisfied: dvc-task<1,>=0.3.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.3.0)\n",
      "Requirement already satisfied: flufl.lock<8,>=5 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (7.1.1)\n",
      "Requirement already satisfied: configobj>=5.0.6 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (5.0.8)\n",
      "Requirement already satisfied: voluptuous>=0.11.7 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.14.0)\n",
      "Requirement already satisfied: dvc-http>=2.29.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (2.30.2)\n",
      "Requirement already satisfied: shortuuid>=0.5 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (1.0.11)\n",
      "Requirement already satisfied: flatten-dict<1,>=0.4.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.4.2)\n",
      "Requirement already satisfied: pygtrie>=2.3.2 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (2.5.0)\n",
      "Requirement already satisfied: shtab<2,>=1.3.4 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (1.6.4)\n",
      "Requirement already satisfied: rich>=12 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (13.6.0)\n",
      "Requirement already satisfied: scmrepo<2,>=1.4.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (3.2.1)\n",
      "Requirement already satisfied: dvc-data<2.21.0,>=2.20.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (2.20.0)\n",
      "Requirement already satisfied: colorama>=0.3.9 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.4.6)\n",
      "Requirement already satisfied: gto<2,>=1.4.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (1.5.0)\n",
      "Requirement already satisfied: platformdirs<4,>=3.1.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (3.11.0)\n",
      "Requirement already satisfied: grandalf<1,>=0.7 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.8)\n",
      "Requirement already satisfied: dvc-render<1,>=0.3.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.6.0)\n",
      "Requirement already satisfied: dpath<3,>=2.1.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (2.1.6)\n",
      "Requirement already satisfied: packaging>=19 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (23.2)\n",
      "Requirement already satisfied: dvc-studio-client<1,>=0.13.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.15.0)\n",
      "Requirement already satisfied: pathspec>=0.10.3 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc) (0.11.2)\n",
      "Requirement already satisfied: six in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from configobj>=5.0.6->dvc) (1.16.0)\n",
      "Requirement already satisfied: dvc-objects<2,>=1.1.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-data<2.21.0,>=2.20.0->dvc) (1.2.0)\n",
      "Requirement already satisfied: sqltrie<1,>=0.8.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-data<2.21.0,>=2.20.0->dvc) (0.8.0)\n",
      "Requirement already satisfied: attrs>=21.3.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-data<2.21.0,>=2.20.0->dvc) (23.1.0)\n",
      "Requirement already satisfied: dictdiffer>=0.8.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-data<2.21.0,>=2.20.0->dvc) (0.9.0)\n",
      "Requirement already satisfied: diskcache>=5.2.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-data<2.21.0,>=2.20.0->dvc) (5.6.3)\n",
      "Requirement already satisfied: aiohttp-retry>=2.5.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-http>=2.29.0->dvc) (2.8.3)\n",
      "Requirement already satisfied: fsspec[http] in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-http>=2.29.0->dvc) (2023.10.0)\n",
      "Requirement already satisfied: dulwich in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-studio-client<1,>=0.13.0->dvc) (0.21.6)\n",
      "Requirement already satisfied: kombu<6,>=5.3.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-task<1,>=0.3.0->dvc) (5.3.3)\n",
      "Requirement already satisfied: celery<6,>=5.3.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-task<1,>=0.3.0->dvc) (5.3.5)\n",
      "Requirement already satisfied: pywin32>=225 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from dvc-task<1,>=0.3.0->dvc) (306)\n",
      "Requirement already satisfied: atpublic>=2.3 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from flufl.lock<8,>=5->dvc) (4.0)\n",
      "Requirement already satisfied: typer>=0.4.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from gto<2,>=1.4.0->dvc) (0.9.0)\n",
      "Requirement already satisfied: pydantic!=2.0.0,<3,>=1.9.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from gto<2,>=1.4.0->dvc) (2.5.0)\n",
      "Requirement already satisfied: semver>=3.0.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from gto<2,>=1.4.0->dvc) (3.0.2)\n",
      "Requirement already satisfied: entrypoints in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from gto<2,>=1.4.0->dvc) (0.4)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from hydra-core>=1.1->dvc) (4.9.3)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from hydra-core>=1.1->dvc) (2.3.0)\n",
      "Requirement already satisfied: appdirs in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from iterative-telemetry>=0.0.7->dvc) (1.4.4)\n",
      "Requirement already satisfied: filelock in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from iterative-telemetry>=0.0.7->dvc) (3.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from requests>=2.22->dvc) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from requests>=2.22->dvc) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from requests>=2.22->dvc) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from requests>=2.22->dvc) (2.1.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from rich>=12->dvc) (2.16.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from rich>=12->dvc) (3.0.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from ruamel.yaml>=0.17.11->dvc) (0.2.8)\n",
      "Requirement already satisfied: asyncssh<3,>=2.13.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from scmrepo<2,>=1.4.1->dvc) (2.14.1)\n",
      "Requirement already satisfied: pygit2>=1.13.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from scmrepo<2,>=1.4.1->dvc) (1.13.2)\n",
      "Requirement already satisfied: gitpython>3 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from scmrepo<2,>=1.4.1->dvc) (3.1.40)\n",
      "Requirement already satisfied: setuptools in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from zc.lockfile>=1.2.1->dvc) (58.1.0)\n",
      "Requirement already satisfied: aiohttp in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (3.8.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from asyncssh<3,>=2.13.1->scmrepo<2,>=1.4.1->dvc) (4.8.0)\n",
      "Requirement already satisfied: cryptography>=39.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from asyncssh<3,>=2.13.1->scmrepo<2,>=1.4.1->dvc) (41.0.5)\n",
      "Requirement already satisfied: click-didyoumean>=0.3.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (0.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (2023.3)\n",
      "Requirement already satisfied: click<9.0,>=8.1.2 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (8.1.7)\n",
      "Requirement already satisfied: billiard<5.0,>=4.2.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (4.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (2.8.2)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (1.1.1)\n",
      "Requirement already satisfied: vine<6.0,>=5.1.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (5.1.0)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (0.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from gitpython>3->scmrepo<2,>=1.4.1->dvc) (4.0.11)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from kombu<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (5.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12->dvc) (0.1.2)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.1->dvc) (6.0.1)\n",
      "Requirement already satisfied: pydantic-core==2.14.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.4.0->dvc) (2.14.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from pydantic!=2.0.0,<3,>=1.9.0->gto<2,>=1.4.0->dvc) (0.6.0)\n",
      "Requirement already satisfied: cffi>=1.16.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from pygit2>=1.13.0->scmrepo<2,>=1.4.1->dvc) (1.16.0)\n",
      "Requirement already satisfied: orjson in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from sqltrie<1,>=0.8.0->dvc-data<2.21.0,>=2.20.0->dvc) (3.9.10)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from aiohttp->aiohttp-retry>=2.5.0->dvc-http>=2.29.0->dvc) (1.3.1)\n",
      "Requirement already satisfied: pycparser in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from cffi>=1.16.0->pygit2>=1.13.0->scmrepo<2,>=1.4.1->dvc) (2.21)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from click-repl>=0.2.0->celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (3.0.41)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>3->scmrepo<2,>=1.4.1->dvc) (5.0.1)\n",
      "Requirement already satisfied: wcwidth in c:\\ecole d'inge\\application of big data\\venv\\lib\\site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery<6,>=5.3.0->dvc-task<1,>=0.3.0->dvc) (0.2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisez un projet dvc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: failed to initiate DVC - c:\\Ecole d'inge\\Application of big data\\.dvc is ignored by your SCM tool. \n",
      "Make sure that it's tracked, for example, by adding '!.dvc' to .gitignore.\n"
     ]
    }
   ],
   "source": [
    "!dvc init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardez ce qui a été créé avec un git status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   .dvcignore\n",
      "\tmodified:   .gitignore\n",
      "\tmodified:   Mlflow_tp_efrei_etudiant.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutez les nouveaux fichiers dans le fichier .dvc : le .gitignore, le fichier config, et le .dvcignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   .dvcignore\n",
      "\tmodified:   .gitignore\n",
      "\tmodified:   Mlflow_tp_efrei_etudiant.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"initialize repo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ajouter un stockage distant dans le cloud. Ici nous allons utiliser un stockage dans un dossier local pour les besoins du tp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'dvc-remote' as a default remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: configuration error - config file error: remote 'dvc-remote' already exists. Use `-f|--force` to overwrite it.\n"
     ]
    }
   ],
   "source": [
    "!dvc remote add -d dvc-remote /tmp/dvc-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut regarder le contenu du fichier dvc config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Get' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ecole d'inge\\Application of big data\\Mlflow_tp_efrei_etudiant.ipynb Cell 61\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#cat .dvc/config\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y114sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Get\u001b[39m-\u001b[39mContent \u001b[39m.\u001b[39mdvc\u001b[39m/\u001b[39mconfig\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Get' is not defined"
     ]
    }
   ],
   "source": [
    "#cat .dvc/config\n",
    "Get-Content .dvc/config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons que l'url locale a bien été ajouté. Nous pouvons commiter ces changements à git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   .dvcignore\n",
      "\tmodified:   .gitignore\n",
      "\tmodified:   Mlflow_tp_efrei_etudiant.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git commit .dvc/config -m \"add remote storage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer un dossier data pour stocker notre dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Un sous-r�pertoire ou un fichier data existe d�j�.\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger notre dataset et le placer dans le dossier data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset_source_url = \"https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\"\n",
    "\n",
    "content = requests.get(dataset_source_url).content\n",
    "with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
    "    raw_data = pd.read_csv(arc.open(\"hour.csv\"), header=0, sep=',', parse_dates=['dteday'], index_col='dteday')\n",
    "\n",
    "raw_data.to_csv(path_or_buf=\"data/hour.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons le contenu de data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle OS\n",
      " Le num�ro de s�rie du volume est 2E08-72D9\n",
      "\n",
      " R�pertoire de c:\\Ecole d'inge\\Application of big data\\data\n",
      "\n",
      "15/11/2023  14:10    <DIR>          .\n",
      "15/11/2023  13:57    <DIR>          ..\n",
      "15/11/2023  13:21                11 .gitignore\n",
      "15/11/2023  14:10         1�161�688 hour.csv\n",
      "15/11/2023  13:28                90 hour.csv.dvc\n",
      "               3 fichier(s)        1�161�789 octets\n",
      "               2 R�p(s)  43�476�619�264 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous voulons commencer à suivre les changements d'un fichier il nous suffit de l'ajouter via dvc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\hour.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/hour.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons regarder de nouveau ce qu'il y a dans notre dossier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle OS"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier introuvable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Le num�ro de s�rie du volume est 2E08-72D9\n",
      "\n",
      " R�pertoire de c:\\Ecole d'inge\\Application of big data\n",
      "\n",
      "\n",
      " R�pertoire de c:\\Ecole d'inge\\Application of big data\\data\n",
      "\n",
      "15/11/2023  14:10    <DIR>          .\n",
      "15/11/2023  13:57    <DIR>          ..\n",
      "15/11/2023  13:21                11 .gitignore\n",
      "15/11/2023  14:10         1�161�688 hour.csv\n",
      "15/11/2023  14:10                96 hour.csv.dvc\n",
      "               3 fichier(s)        1�161�795 octets\n",
      "               2 R�p(s)  43�475�259�392 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls -l data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons un nouveau fichier .dvc.   \n",
    "Si nous regardons à l'intérieur : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Get-Content' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!Get-Content data/hour.csv.dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que le fichier contient des informations à propos de notre csv :  \n",
    "- Un hash du fichier \n",
    "- l'algorithme de hashage utilisé\n",
    "- la taille\n",
    "- le chemin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un gitignore a été créé par défaut, si on regarde à l'intérieur : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Get-Content' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!Get-Content data/.gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que notre csv y est renseigné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant ajoutons le nouveau fichier data/hour.csv.dvc et le fichier data/.gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add data/.gitignore data/hour.csv.dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et commitons le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master bf79dbb] add .dvc file to track hours.csv file\n",
      " 1 file changed, 2 insertions(+), 2 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"add .dvc file to track hours.csv file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une bonne idée est de créer un tag pour chaque version de notre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: tag ''v1'' already exists\n"
     ]
    }
   ],
   "source": [
    "!git tag -a 'v1' -m 'raw_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre donnée est toujours sur notre dossier en local, maintenant nous devons l'envoyer sur notre stokage distant (qui pour rappel et en fait un autre dossier local). Pour ça nous utilisons la commande dvc push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut regarder dans notre \"remote storage\" ce que nous avons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Le format du param�tre est incorrect - \"mp\".\n"
     ]
    }
   ],
   "source": [
    "ls -lR /tmp/dvc-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que notre fichier est présent dans le dossier mais avec un nom différent, ce nom correspond au hash de la donnée du fichier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nos données sont sauvegardées à distance, nous pouvons les supprimer localement. Sauf le fichier .dvc ! Car sinon vous perdrez le lien avec vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle OS\n",
      " Le num�ro de s�rie du volume est 2E08-72D9\n",
      "\n",
      " R�pertoire de c:\\Ecole d'inge\\Application of big data\\data\n",
      "\n",
      "15/11/2023  14:10    <DIR>          .\n",
      "15/11/2023  13:57    <DIR>          ..\n",
      "15/11/2023  13:21                11 .gitignore\n",
      "15/11/2023  14:10         1�161�688 hour.csv\n",
      "15/11/2023  14:10                96 hour.csv.dvc\n",
      "               3 fichier(s)        1�161�795 octets\n",
      "               2 R�p(s)  43�478�331�392 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!rm -r data/hour.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un autre emplacement où vos données résident est le dossier .dvc/cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n",
      "'Get-Content' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!ls .dvc/cache/files/md5/0a/1c63297d478edfdcc18433bb509cd5\n",
    "!Get-Content .dvc/cache/files/md5/0a/1c63297d478edfdcc18433bb509cd5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous supprimons aussi les données à l'intérieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!rm -r .dvc/cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous voulons récupérer nos données localement, nous pouvons utiliser dvc pull pour récupérer les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous regardons dans le dossier data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle OS\n",
      " Le num�ro de s�rie du volume est 2E08-72D9\n",
      "\n",
      " R�pertoire de c:\\Ecole d'inge\\Application of big data\n",
      "\n",
      "\n",
      " R�pertoire de c:\\Ecole d'inge\\Application of big data\\data\n",
      "\n",
      "15/11/2023  14:10    <DIR>          .\n",
      "15/11/2023  13:57    <DIR>          ..\n",
      "15/11/2023  13:21                11 .gitignore\n",
      "15/11/2023  14:10         1�161�688 hour.csv\n",
      "15/11/2023  14:10                96 hour.csv.dvc\n",
      "               3 fichier(s)        1�161�795 octets\n",
      "               2 R�p(s)  43�477�733�376 octets libres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier introuvable\n"
     ]
    }
   ],
   "source": [
    "ls -l data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre fichier est de retour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant modifions nos données !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Option non valide - \"hour.csv\".\n"
     ]
    }
   ],
   "source": [
    "ls data/hour.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-replace �tait inattendu.\n"
     ]
    }
   ],
   "source": [
    "!(Get-Content -Path \"data/hour.csv\" -Raw) -replace \"(?m)^.*\\r?\\n\", \"\" | Set-Content -Path \"data/hour.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/hour.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et répétons les opérations précédantes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\hour.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dvc add data/hour.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add data/hour.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: pathspec 'remove' did not match any file(s) known to git\n",
      "error: pathspec '1000' did not match any file(s) known to git\n",
      "error: pathspec 'lines'' did not match any file(s) known to git\n"
     ]
    }
   ],
   "source": [
    "!git commit -m 'data: remove 1000 lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: too many arguments\n"
     ]
    }
   ],
   "source": [
    "!git tag -a 'v2' -m 'removed 1000 lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "!dvc push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!rm -r data/hour.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf .dvc/cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant regarder dans notre git log, et voir l'historique des modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commit bf79dbbafba76f1d812ed9849ef932fa0bf391ec\n",
      "Author: STANG94 <stephane.tang@efrei.net>\n",
      "Date:   Wed Nov 15 14:11:08 2023 +0100\n",
      "\n",
      "    add .dvc file to track hours.csv file\n",
      "\n",
      "commit 73490a1a4d8c2e34652265a53de3d2c276c4fcdd\n",
      "Author: STANG94 <stephane.tang@efrei.net>\n",
      "Date:   Wed Nov 15 14:07:49 2023 +0100\n",
      "\n",
      "    test1\n",
      "\n",
      "commit c851f3c9d8f7ab0160cfef03ca7e001663d5ac03\n",
      "Author: STANG94 <stephane.tang@efrei.net>\n",
      "Date:   Wed Nov 15 14:06:19 2023 +0100\n",
      "\n",
      "    test\n",
      "\n",
      "commit ee3cae28bceff5f10aceb7db628d045cb5cbe2b3\n",
      "Author: STANG94 <stephane.tang@efrei.net>\n",
      "Date:   Wed Nov 15 13:58:34 2023 +0100\n",
      "\n",
      "    test\n",
      "\n",
      "commit 2fc018930fdde1f12113fa77e531147b45eb551f\n",
      "Author: STANG94 <stephane.tang@efrei.net>\n",
      "Date:   Wed Nov 15 13:23:01 2023 +0100\n",
      "\n",
      "    add .dvc file to track hours.csv file\n",
      "\n",
      "commit e5664c16479717c59ea4484ad6e8d54d32a48ed4\n",
      "Author: STANG94 <stephane.tang@efrei.net>\n",
      "Date:   Wed Nov 15 13:21:01 2023 +0100\n",
      "\n",
      "    add remote storage\n",
      "\n",
      "commit 3b06766748f86bcc54dd6b0c9ade031020721bcf\n",
      "Author: STANG94 <stephane.tang@efrei.net>\n",
      "Date:   Wed Nov 15 13:17:43 2023 +0100\n",
      "\n",
      "    initialize repo\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour accéder et extraire des versions spécifiques de nos données nous pouvons utiliser le package dvc en python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'Select-String' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nOutput\\ndvc==3.29.0\\ndvc-data==2.20.0\\ndvc-http==2.30.2\\ndvc-objects==1.2.0\\ndvc-render==0.6.0\\ndvc-studio-client==0.15.0\\ndvc-task==0.3.0\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip freeze | Select-String -Pattern \"dvc\"\n",
    "\n",
    "\"\"\"\n",
    "Output\n",
    "dvc==3.29.0\n",
    "dvc-data==2.20.0\n",
    "dvc-http==2.30.2\n",
    "dvc-objects==1.2.0\n",
    "dvc-render==0.6.0\n",
    "dvc-studio-client==0.15.0\n",
    "dvc-task==0.3.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dvc\n",
    "import dvc.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "CloneError",
     "evalue": "SCM error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotGitRepository\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\scmrepo\\git\\backend\\dulwich\\__init__.py:227\u001b[0m, in \u001b[0;36mDulwichBackend.clone\u001b[1;34m(cls, url, to_path, shallow_branch, progress, bare, mirror)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     repo \u001b[39m=\u001b[39m clone_from()\n\u001b[0;32m    229\u001b[0m \u001b[39mwith\u001b[39;00m closing(repo):\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dulwich\\porcelain.py:542\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(source, target, bare, checkout, errstream, outstream, origin, depth, branch, config, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m (client, path) \u001b[39m=\u001b[39m get_transport_and_path(\n\u001b[0;32m    540\u001b[0m     source, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 542\u001b[0m \u001b[39mreturn\u001b[39;00m client\u001b[39m.\u001b[39;49mclone(\n\u001b[0;32m    543\u001b[0m     path,\n\u001b[0;32m    544\u001b[0m     target,\n\u001b[0;32m    545\u001b[0m     mkdir\u001b[39m=\u001b[39;49mmkdir,\n\u001b[0;32m    546\u001b[0m     bare\u001b[39m=\u001b[39;49mbare,\n\u001b[0;32m    547\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n\u001b[0;32m    548\u001b[0m     checkout\u001b[39m=\u001b[39;49mcheckout,\n\u001b[0;32m    549\u001b[0m     branch\u001b[39m=\u001b[39;49mbranch,\n\u001b[0;32m    550\u001b[0m     progress\u001b[39m=\u001b[39;49merrstream\u001b[39m.\u001b[39;49mwrite,\n\u001b[0;32m    551\u001b[0m     depth\u001b[39m=\u001b[39;49mdepth,\n\u001b[0;32m    552\u001b[0m )\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dulwich\\client.py:738\u001b[0m, in \u001b[0;36mGitClient.clone\u001b[1;34m(self, path, target_path, mkdir, bare, origin, checkout, branch, progress, depth)\u001b[0m\n\u001b[0;32m    737\u001b[0m ref_message \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mclone: from \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m encoded_path\n\u001b[1;32m--> 738\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch(path, target, progress\u001b[39m=\u001b[39;49mprogress, depth\u001b[39m=\u001b[39;49mdepth)\n\u001b[0;32m    739\u001b[0m _import_remote_refs(\n\u001b[0;32m    740\u001b[0m     target\u001b[39m.\u001b[39mrefs, origin, result\u001b[39m.\u001b[39mrefs, message\u001b[39m=\u001b[39mref_message)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dulwich\\client.py:1484\u001b[0m, in \u001b[0;36mLocalGitClient.fetch\u001b[1;34m(self, path, target, determine_wants, progress, depth)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fetch into a target repository.\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m \n\u001b[0;32m   1471\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \n\u001b[0;32m   1483\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1484\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open_repo(path) \u001b[39mas\u001b[39;00m r:\n\u001b[0;32m   1485\u001b[0m     refs \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mfetch(\n\u001b[0;32m   1486\u001b[0m         target,\n\u001b[0;32m   1487\u001b[0m         determine_wants\u001b[39m=\u001b[39mdetermine_wants,\n\u001b[0;32m   1488\u001b[0m         progress\u001b[39m=\u001b[39mprogress,\n\u001b[0;32m   1489\u001b[0m         depth\u001b[39m=\u001b[39mdepth,\n\u001b[0;32m   1490\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dulwich\\client.py:1406\u001b[0m, in \u001b[0;36mLocalGitClient._open_repo\u001b[1;34m(cls, path)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfsdecode(path)\n\u001b[1;32m-> 1406\u001b[0m \u001b[39mreturn\u001b[39;00m closing(Repo(path))\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dulwich\\repo.py:1141\u001b[0m, in \u001b[0;36mRepo.__init__\u001b[1;34m(self, root, object_store, bare)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1141\u001b[0m         \u001b[39mraise\u001b[39;00m NotGitRepository(\n\u001b[0;32m   1142\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNo git repository was found at \u001b[39m\u001b[39m{path}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(path\u001b[39m=\u001b[39mroot))\n\u001b[0;32m   1143\u001b[0m         )\n\u001b[0;32m   1145\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbare \u001b[39m=\u001b[39m bare\n",
      "\u001b[1;31mNotGitRepository\u001b[0m: No git repository was found at dvc-remote",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mCloneError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\scm.py:158\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(url, to_path, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     git \u001b[39m=\u001b[39m Git\u001b[39m.\u001b[39mclone(url, to_path, progress\u001b[39m=\u001b[39mpbar\u001b[39m.\u001b[39mupdate_git, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    159\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mshallow_branch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\scmrepo\\git\\__init__.py:148\u001b[0m, in \u001b[0;36mGit.clone\u001b[1;34m(cls, url, to_path, rev, bare, mirror, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m     backend\u001b[39m.\u001b[39mclone(url, to_path, bare\u001b[39m=\u001b[39mbare, mirror\u001b[39m=\u001b[39mmirror, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    149\u001b[0m     repo \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(to_path)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\scmrepo\\git\\backend\\dulwich\\__init__.py:235\u001b[0m, in \u001b[0;36mDulwichBackend.clone\u001b[1;34m(cls, url, to_path, shallow_branch, progress, bare, mirror)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> 235\u001b[0m     \u001b[39mraise\u001b[39;00m CloneError(url, to_path) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mCloneError\u001b[0m: Failed to clone repo 'dvc-remote' to 'C:\\Users\\tangs\\AppData\\Local\\Temp\\tmp5wzkk9ukdvc-clone'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mCloneError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ecole d'inge\\Application of big data\\Mlflow_tp_efrei_etudiant.ipynb Cell 121\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y231sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2fc018930fdde1f12113fa77e531147b45eb551f\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y231sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#revision can be git commit id, commit tag, ...\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y231sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data_url \u001b[39m=\u001b[39m dvc\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mget_url(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y231sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     path\u001b[39m=\u001b[39;49mpath, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y231sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     repo\u001b[39m=\u001b[39;49mrepo,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y231sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     rev\u001b[39m=\u001b[39;49mversion\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Ecole%20d%27inge/Application%20of%20big%20data/Mlflow_tp_efrei_etudiant.ipynb#Y231sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\api\\data.py:45\u001b[0m, in \u001b[0;36mget_url\u001b[1;34m(path, repo, rev, remote)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m remote:\n\u001b[0;32m     44\u001b[0m     repo_kwargs[\u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcore\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mremote\u001b[39m\u001b[39m\"\u001b[39m: remote}}\n\u001b[1;32m---> 45\u001b[0m \u001b[39mwith\u001b[39;00m Repo\u001b[39m.\u001b[39mopen(\n\u001b[0;32m     46\u001b[0m     repo, rev\u001b[39m=\u001b[39mrev, subrepos\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, uninitialized\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrepo_kwargs\n\u001b[0;32m     47\u001b[0m ) \u001b[39mas\u001b[39;00m _repo:\n\u001b[0;32m     48\u001b[0m     index, entry \u001b[39m=\u001b[39m _repo\u001b[39m.\u001b[39mget_data_index_entry(path)\n\u001b[0;32m     49\u001b[0m     \u001b[39mwith\u001b[39;00m reraise(\n\u001b[0;32m     50\u001b[0m         (StorageKeyError, \u001b[39mValueError\u001b[39;00m),\n\u001b[0;32m     51\u001b[0m         NoRemoteError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno remote specified in \u001b[39m\u001b[39m{\u001b[39;00m_repo\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     52\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\repo\\__init__.py:304\u001b[0m, in \u001b[0;36mRepo.open\u001b[1;34m(url, *args, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(url: Optional[\u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRepo\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# noqa: A003\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mopen_repo\u001b[39;00m \u001b[39mimport\u001b[39;00m open_repo\n\u001b[1;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m open_repo(url, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\repo\\open_repo.py:64\u001b[0m, in \u001b[0;36mopen_repo\u001b[1;34m(url, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[39mexcept\u001b[39;00m NotDvcRepoError:\n\u001b[0;32m     62\u001b[0m         \u001b[39mpass\u001b[39;00m  \u001b[39m# fallthrough to _external_repo\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[39mreturn\u001b[39;00m _external_repo(url, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Ecole9\\lib\\contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\repo\\open_repo.py:27\u001b[0m, in \u001b[0;36m_external_repo\u001b[1;34m(url, rev, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m@map_scm_exception\u001b[39m()\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_external_repo\u001b[39m(\n\u001b[0;32m     22\u001b[0m     url,\n\u001b[0;32m     23\u001b[0m     rev: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     24\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     25\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRepo\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     26\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating external repo \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m@\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, rev)\n\u001b[1;32m---> 27\u001b[0m     path \u001b[39m=\u001b[39m _cached_clone(url, rev)\n\u001b[0;32m     28\u001b[0m     \u001b[39m# Local HEAD points to the tip of whatever branch we first cloned from\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[39m# (which may not be the default branch), use origin/HEAD here to get\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[39m# the tip of the default branch\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     rev \u001b[39m=\u001b[39m rev \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrefs/remotes/origin/HEAD\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\repo\\open_repo.py:138\u001b[0m, in \u001b[0;36m_cached_clone\u001b[1;34m(url, rev)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mshutil\u001b[39;00m \u001b[39mimport\u001b[39;00m copytree\n\u001b[0;32m    136\u001b[0m \u001b[39m# even if we have already cloned this repo, we may need to\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39m# fetch/fast-forward to get specified rev\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m clone_path, shallow \u001b[39m=\u001b[39m _clone_default_branch(url, rev)\n\u001b[0;32m    140\u001b[0m \u001b[39mif\u001b[39;00m url \u001b[39min\u001b[39;00m CLONES:\n\u001b[0;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m CLONES[url][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\funcy\\decorators.py:47\u001b[0m, in \u001b[0;36mmake_decorator.<locals>._decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     call \u001b[39m=\u001b[39m Call(func, args, kwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m deco(call, \u001b[39m*\u001b[39mdargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdkwargs)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\funcy\\flow.py:246\u001b[0m, in \u001b[0;36mwrap_with\u001b[1;34m(call, ctx)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Turn context manager into a decorator\"\"\"\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39mwith\u001b[39;00m ctx:\n\u001b[1;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m call()\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\funcy\\decorators.py:68\u001b[0m, in \u001b[0;36mCall.__call__\u001b[1;34m(self, *a, **kw)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[0;32m     67\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m a \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw:\n\u001b[1;32m---> 68\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs)\n\u001b[0;32m     69\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func(\u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args \u001b[39m+\u001b[39m a), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw))\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\repo\\open_repo.py:202\u001b[0m, in \u001b[0;36m_clone_default_branch\u001b[1;34m(url, rev)\u001b[0m\n\u001b[0;32m    200\u001b[0m             _remove(git_dir)\n\u001b[0;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m git:\n\u001b[1;32m--> 202\u001b[0m     git \u001b[39m=\u001b[39m clone(url, clone_path)\n\u001b[0;32m    203\u001b[0m     shallow \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    204\u001b[0m CLONES[url] \u001b[39m=\u001b[39m (clone_path, shallow)\n",
      "File \u001b[1;32mc:\\Ecole d'inge\\Application of big data\\venv\\lib\\site-packages\\dvc\\scm.py:163\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(url, to_path, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m git\n\u001b[0;32m    162\u001b[0m \u001b[39mexcept\u001b[39;00m InternalCloneError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> 163\u001b[0m     \u001b[39mraise\u001b[39;00m CloneError(\u001b[39m\"\u001b[39m\u001b[39mSCM error\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mCloneError\u001b[0m: SCM error"
     ]
    }
   ],
   "source": [
    "path=\"data/hour.csv.dvc\"\n",
    "repo=\"dvc-remote\"\n",
    "version=\"bf79dbbafba76f1d812ed9849ef932fa0bf391ec\"\n",
    "\n",
    "#revision can be git commit id, commit tag, ...\n",
    "\n",
    "data_url = dvc.api.get_url(\n",
    "    path=path, \n",
    "    repo=repo,\n",
    "    rev=version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "print(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'389645318088192245'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "configure_experiment(name=\"ML_EXP_WITH_DVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dteday  instant  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0  2011-01-01        1       1   0     1   0        0        6           0   \n",
      "1  2011-01-01        2       1   0     1   1        0        6           0   \n",
      "2  2011-01-01        3       1   0     1   2        0        6           0   \n",
      "3  2011-01-01        4       1   0     1   3        0        6           0   \n",
      "4  2011-01-01        5       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_url, sep=\",\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "\n",
    "data.index = raw_data.apply(\n",
    "    lambda row: datetime.combine(row.name, time(hour=int(row['hr']))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         dteday  instant  season  yr  mnth  hr  holiday  \\\n",
       "2011-01-01 00:00:00  2011-01-01        1       1   0     1   0        0   \n",
       "2011-01-01 01:00:00  2011-01-01        2       1   0     1   1        0   \n",
       "2011-01-01 02:00:00  2011-01-01        3       1   0     1   2        0   \n",
       "2011-01-01 03:00:00  2011-01-01        4       1   0     1   3        0   \n",
       "2011-01-01 04:00:00  2011-01-01        5       1   0     1   4        0   \n",
       "\n",
       "                     weekday  workingday  weathersit  temp   atemp   hum  \\\n",
       "2011-01-01 00:00:00        6           0           1  0.24  0.2879  0.81   \n",
       "2011-01-01 01:00:00        6           0           1  0.22  0.2727  0.80   \n",
       "2011-01-01 02:00:00        6           0           1  0.22  0.2727  0.80   \n",
       "2011-01-01 03:00:00        6           0           1  0.24  0.2879  0.75   \n",
       "2011-01-01 04:00:00        6           0           1  0.24  0.2879  0.75   \n",
       "\n",
       "                     windspeed  casual  registered  cnt  \n",
       "2011-01-01 00:00:00        0.0       3          13   16  \n",
       "2011-01-01 01:00:00        0.0       8          32   40  \n",
       "2011-01-01 02:00:00        0.0       5          27   32  \n",
       "2011-01-01 03:00:00        0.0       3          10   13  \n",
       "2011-01-01 04:00:00        0.0       0           1    1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant utiliser 2 mécanismes pour ajouter plus d'informations sur notre jeu de données dans MLFlow :    \n",
    "-Grâce à dvc, nous avons maintenant des liens vers les différentes versions de notre jeu de données.   \n",
    "-Nous pouvons l'utiliser en combinaison avec le module mlflow.data pour ajouter plus d'informations sur notre jeu de données.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cnt'\n",
    "prediction = 'prediction'\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'hr', 'weekday']\n",
    "categorical_features = ['season', 'holiday', 'workingday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2011-01-01 00:00:00'\n",
    "end_date = '2011-01-28 23:00:00'\n",
    "dataset = data.loc[start_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         dteday  instant  season  yr  mnth  hr  holiday  \\\n",
      "2011-01-01 00:00:00  2011-01-01        1       1   0     1   0        0   \n",
      "2011-01-01 01:00:00  2011-01-01        2       1   0     1   1        0   \n",
      "2011-01-01 02:00:00  2011-01-01        3       1   0     1   2        0   \n",
      "2011-01-01 03:00:00  2011-01-01        4       1   0     1   3        0   \n",
      "2011-01-01 04:00:00  2011-01-01        5       1   0     1   4        0   \n",
      "...                         ...      ...     ...  ..   ...  ..      ...   \n",
      "2011-01-28 19:00:00  2011-01-28      614       1   0     1  19        0   \n",
      "2011-01-28 20:00:00  2011-01-28      615       1   0     1  20        0   \n",
      "2011-01-28 21:00:00  2011-01-28      616       1   0     1  21        0   \n",
      "2011-01-28 22:00:00  2011-01-28      617       1   0     1  22        0   \n",
      "2011-01-28 23:00:00  2011-01-28      618       1   0     1  23        0   \n",
      "\n",
      "                     weekday  workingday  weathersit  temp   atemp   hum  \\\n",
      "2011-01-01 00:00:00        6           0           1  0.24  0.2879  0.81   \n",
      "2011-01-01 01:00:00        6           0           1  0.22  0.2727  0.80   \n",
      "2011-01-01 02:00:00        6           0           1  0.22  0.2727  0.80   \n",
      "2011-01-01 03:00:00        6           0           1  0.24  0.2879  0.75   \n",
      "2011-01-01 04:00:00        6           0           1  0.24  0.2879  0.75   \n",
      "...                      ...         ...         ...   ...     ...   ...   \n",
      "2011-01-28 19:00:00        5           1           2  0.24  0.2424  0.75   \n",
      "2011-01-28 20:00:00        5           1           2  0.24  0.2273  0.70   \n",
      "2011-01-28 21:00:00        5           1           2  0.22  0.2273  0.75   \n",
      "2011-01-28 22:00:00        5           1           1  0.24  0.2121  0.65   \n",
      "2011-01-28 23:00:00        5           1           1  0.24  0.2273  0.60   \n",
      "\n",
      "                     windspeed  casual  registered  cnt  \n",
      "2011-01-01 00:00:00     0.0000       3          13   16  \n",
      "2011-01-01 01:00:00     0.0000       8          32   40  \n",
      "2011-01-01 02:00:00     0.0000       5          27   32  \n",
      "2011-01-01 03:00:00     0.0000       3          10   13  \n",
      "2011-01-01 04:00:00     0.0000       0           1    1  \n",
      "...                        ...     ...         ...  ...  \n",
      "2011-01-28 19:00:00     0.1343       5          84   89  \n",
      "2011-01-28 20:00:00     0.1940       1          61   62  \n",
      "2011-01-28 21:00:00     0.1343       1          57   58  \n",
      "2011-01-28 22:00:00     0.3582       0          26   26  \n",
      "2011-01-28 23:00:00     0.2239       1          22   23  \n",
      "\n",
      "[618 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la même cellule : \n",
    "\n",
    "1)\n",
    "- Aller voir la documentation du module mlflow data et importer le bon objet pour les données pandas.  \n",
    "- Créer un run avec la date, l'heure, etc. comme nom.    \n",
    "- pour l'entrainement vous pouvez utiliser le chemin vers votre dataset lors de la création de votre dataframe.   \n",
    "\n",
    "2) \n",
    "- logger le dataset avec la méthode appropriée.  \n",
    "- logger également le chemin vers votre dataset.   \n",
    "- logger la version du dataset utilisée.   \n",
    "\n",
    "3)\n",
    "- Créer un fichier texte et logger le en tant qu'artifact. Dans ce fichier vous pourrez indiquer la colonne qui a servi de target, les features numériques et les features catégorielles.\n",
    "\n",
    "4)\n",
    "- N'oubliez pas d'utiliser la fonction mlflow.end_run() si vous n'avez pas utilisez de with pour le run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Déploiement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Trouver comment transitionner un modèle en état staging et ensuite dans l'état production. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Créer une fonction qui récupère la version du modèle avec les meilleurs metrics d'entraînement et qui transitionne ce modèle dans l'état production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Le serveur mlflow peut vous fournir des prédictions à partir des modèles enregistrés. Faites en sorte d'obtenir une prédiction de votre dernier modèle en requêtant le serveur mlflow. (Voir : https://mlflow.org/docs/latest/models.html#command-line-interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Créer un script à part qui pull le dernier modèle depuis le model registry. Plus tard vous pourrez utiliser ce script pour récupérer le modèle dans une api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Entraînement d'un CNN et log des metrics dans MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voir le notebook donnée par le formateur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_tp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
